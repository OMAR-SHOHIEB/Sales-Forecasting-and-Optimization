{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "def preprocess_data(df):\n",
    "    # Convert date to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Create temporal features\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['day_of_month'] = df['date'].dt.day\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le = LabelEncoder()\n",
    "    df['country_encoded'] = le.fit_transform(df['country'])\n",
    "    df['store_encoded'] = le.fit_transform(df['store'])\n",
    "    df['product_encoded'] = le.fit_transform(df['product'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "def get_feature_columns():\n",
    "    return ['year', 'month', 'day_of_week', 'day_of_month', \n",
    "            'country_encoded', 'store_encoded', 'product_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models\n",
    "def evaluate_models(df):\n",
    "    df = preprocess_data(df)\n",
    "    features = get_feature_columns()\n",
    "    target = 'num_sold'\n",
    "    \n",
    "    # Time series split for validation\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    models = {\n",
    "        'XGBoost': XGBRegressor(random_state=42),\n",
    "        'LightGBM': LGBMRegressor(random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        rmse_scores = []\n",
    "        mae_scores = []\n",
    "        r2_scores = []\n",
    "        \n",
    "        for train_idx, test_idx in tscv.split(df):\n",
    "            X_train = df.iloc[train_idx][features]\n",
    "            y_train = df.iloc[train_idx][target]\n",
    "            X_test = df.iloc[test_idx][features]\n",
    "            y_test = df.iloc[test_idx][target]\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X_test)\n",
    "            \n",
    "            rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "            mae = mean_absolute_error(y_test, predictions)\n",
    "            r2 = r2_score(y_test, predictions)\n",
    "            \n",
    "            r2_scores.append(r2)\n",
    "            rmse_scores.append(rmse)\n",
    "            mae_scores.append(mae)\n",
    "        \n",
    "        results[name] = {\n",
    "            'RMSE': np.mean(rmse_scores),\n",
    "            'MAE': np.mean(mae_scores),\n",
    "            'R2': np.mean(r2_scores)\n",
    "        }\n",
    "    \n",
    "    # Prophet model evaluation\n",
    "    prophet_df = df[['date', target]].rename(columns={'date': 'ds', target: 'y'})\n",
    "    prophet_rmse = []\n",
    "    prophet_mae = []\n",
    "    prophet_r2 = []\n",
    "    \n",
    "    for train_idx, test_idx in tscv.split(prophet_df):\n",
    "        train_data = prophet_df.iloc[train_idx]\n",
    "        test_data = prophet_df.iloc[test_idx]\n",
    "        \n",
    "        model = Prophet(yearly_seasonality=True, weekly_seasonality=True)\n",
    "        model.fit(train_data)\n",
    "        \n",
    "        future_dates = test_data[['ds']]\n",
    "        forecast = model.predict(future_dates)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(test_data['y'], forecast['yhat']))\n",
    "        mae = mean_absolute_error(test_data['y'], forecast['yhat'])\n",
    "        r2 = r2_score(test_data['y'], forecast['yhat'])\n",
    "        \n",
    "        prophet_r2.append(r2)\n",
    "        prophet_rmse.append(rmse)\n",
    "        prophet_mae.append(mae)\n",
    "    \n",
    "    results['Prophet'] = {\n",
    "        'RMSE': np.mean(prophet_rmse),\n",
    "        'MAE': np.mean(prophet_mae),\n",
    "        'R2': np.mean(prophet_r2)\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57\n",
      "[LightGBM] [Info] Number of data points in the train set: 4383, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 374.786676\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 63\n",
      "[LightGBM] [Info] Number of data points in the train set: 8766, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 374.012092\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 63\n",
      "[LightGBM] [Info] Number of data points in the train set: 13149, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 364.119781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 64\n",
      "[LightGBM] [Info] Number of data points in the train set: 17532, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 374.060005\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 65\n",
      "[LightGBM] [Info] Number of data points in the train set: 21915, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 384.192836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:21:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:21:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:21:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:21:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:21:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:21:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:21:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:21:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:21:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:21:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation Results:\n",
      "\n",
      "XGBoost:\n",
      "RMSE: 70.50\n",
      "MAE: 40.07\n",
      "R2: 0.92\n",
      "\n",
      "LightGBM:\n",
      "RMSE: 65.55\n",
      "MAE: 35.61\n",
      "R2: 0.93\n",
      "\n",
      "Prophet:\n",
      "RMSE: 264.43\n",
      "MAE: 196.98\n",
      "R2: -0.01\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Load data\n",
    "    df = pd.read_csv('train.csv')\n",
    "    \n",
    "    # Evaluate models\n",
    "    results = evaluate_models(df)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nModel Evaluation Results:\")\n",
    "    for model, metrics in results.items():\n",
    "        print(f\"\\n{model}:\")\n",
    "        print(f\"RMSE: {metrics['RMSE']:.2f}\")\n",
    "        print(f\"MAE: {metrics['MAE']:.2f}\")\n",
    "        print(f\"R2: {metrics['R2']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
